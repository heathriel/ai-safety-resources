# Additional AI Safety Resources

## 1. AI Risk Repository by MIT
- **Description**: A comprehensive database cataloging over 700 risks associated with AI, aiming to raise awareness and head off problems before they arise.
- **Link**: [AI Risk Repository](https://airisk.mit.edu/)

---

## 2. Teeny-Tiny Castle: Educational Tools for AI Ethics and Safety Research
- **Description**: An open-source repository containing educational tools for AI ethics and safety research, providing examples of AI safety problems and solutions.
- **Link**: [Teeny-Tiny Castle](https://github.com/Nkluge-correa/TeenyTinyCastle)

---

## 3. IEEE Program for Free Access to AI Ethics and Governance Standards (2023)
- **Description**: A program by IEEE providing free access to global sociotechnical standards in AI ethics and governance.
- **Link**: [IEEE AI Ethics Standards](https://standards.ieee.org/news/get-program-ai-ethics/)

---

## 4. Worldwide AI Ethics: A Review of 200 Guidelines and Recommendations for AI Governance (2022)
- **Description**: A comprehensive review of AI ethics guidelines and recommendations globally, providing insights into AI governance.
- **Link**: [Worldwide AI Ethics Review](https://arxiv.org/abs/2206.11922)

---

## 5. AI Ethics Principles for Legal Professionals (2024)
- **Description**: Guidelines emphasizing the ethical use of Generative AI (GenAI) in legal practice, focusing on competence, confidentiality, consent, and other key principles.
- **Link**: [Ethical Use of AI by Lawyers](https://www.reuters.com/legal/legalindustry/navigating-seven-cs-ethical-use-ai-by-lawyers-2024-12-20/)

---

## 6. Center for AI Safety (CAIS)
- **Description**: A San Francisco-based nonprofit dedicated to reducing societal-scale risks from AI through research and field-building initiatives.
- **Link**: [CAIS](https://www.safe.ai/)

---

## 7. U.S. Artificial Intelligence Safety Institute (AISI)
- **Description**: An initiative by NIST focusing on advancing research and measurement science for AI safety, conducting safety evaluations, and developing guidelines for risk mitigation.
- **Link**: [U.S. Artificial Intelligence Safety Institute (AISI)](https://www.nist.gov/aisi)

---

## 8. AI Safety and Governance Fund
- **Description**: A nonprofit dedicated to ensuring that AI and other technologies benefit humanity and are developed safely, securely, and in alignment with human values.
- **Link**: [AI Safety and Governance Fund](https://aisgf.us/)

---

## 9. AI Safety Guide
- **Description**: A comprehensive introduction to AI safety, providing insights into the field and guidance on mitigating risks associated with advanced AI.
- **Link**: [AI Safety Guide](https://www.aisafety.com/)

---

## 10. Our Approach to AI Safety by OpenAI
- **Description**: An overview of OpenAI’s practical approach to addressing AI safety concerns, including research on effective mitigations and alignment techniques.
- **Link**: [OpenAI’s Approach to AI Safety](https://openai.com/index/our-approach-to-ai-safety/)